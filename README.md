# Plano Estrat√©gico de Testes (Alto N√≠vel)

Este documento descreve o plano estrat√©gico de testes para garantir a qualidade e estabilidade da aplica√ß√£o antes do seu go-live. Ele cobre a abordagem geral de testes, tipos de testes adotados, framework utilizado, riscos, premissas, cen√°rios cr√≠ticos e as principais m√©tricas de qualidade que devem ser acompanhadas ao longo do processo.

---

## üß± Arquitetura da Aplica√ß√£o e Pontos de Falha

A aplica√ß√£o segue uma arquitetura baseada em **frontend web**, **backend (API REST)** e um servi√ßo de **OCR para leitura de arquivos PDF**. O upload de documentos √© feito via UI, processado pelo backend e enviado ao servi√ßo OCR para extra√ß√£o de dados.

### Pontos cr√≠ticos potenciais:
- ‚ùå Falhas no upload ou valida√ß√£o de arquivos PDF (ex: tamanho, formato).
- ‚ùå Comunica√ß√£o inst√°vel entre frontend ‚Üî backend ou backend ‚Üî OCR.
- ‚ùå Respostas incorretas ou inconsistentes da API OCR.
- ‚ùå Processamento de arquivos demorando al√©m do aceit√°vel.
- ‚ùå Regress√µes em funcionalidades cr√≠ticas j√° implementadas.

---

## ‚úÖ Tipos de Testes e Justificativa

| Tipo de Teste          | Descri√ß√£o                                                                 | Justificativa |
|------------------------|---------------------------------------------------------------------------|----------------|
| **Testes Unit√°rios**   | Validam fun√ß√µes isoladas, como valida√ß√µes de extens√£o ou tamanho de arquivos. | Garante que a l√≥gica de neg√≥cios funcione corretamente. |
| **Testes de Integra√ß√£o** | Verificam a intera√ß√£o entre componentes (ex: envio de PDF ‚Üí resposta do OCR). | Assegura que os m√≥dulos se comuniquem corretamente. |
| **Testes de Contrato** | Validam os contratos da API (ex: schema de resposta do OCR).                | Prev√™m que mudan√ßas na API n√£o quebrem o sistema. |
| **Testes de Regress√£o** | Validam funcionalidades cr√≠ticas sempre que houver deploy ou merge.         | Evitam que novas mudan√ßas quebrem o que j√° est√° funcionando. |
| **Testes End-to-End (E2E)** | Automatizam fluxos reais do usu√°rio com Cypress.                        | Garante que o sistema funciona como um todo em ambientes reais. |

---

## üß∞ Framework de Testes Escolhido

**Framework:** [Cypress](https://www.cypress.io/)

### ‚úî Justificativa T√©cnica:
- ‚úÖ **Simples de configurar e usar**, com uma curva de aprendizado suave para a equipe de QA.
- ‚úÖ Permite testes **E2E, integra√ß√£o e API** no mesmo ambiente.
- ‚úÖ **Alta performance** por rodar diretamente no navegador, com capacidade de debug visual.
- ‚úÖ Suporte robusto a **mocks**, **intercepta√ß√µes de rede** e **simula√ß√£o de falhas em APIs**.
- ‚úÖ Integra√ß√£o nativa com **GitHub Actions** e gera√ß√£o de relat√≥rios com **Allure**.
- ‚úÖ Ampla comunidade e excelente documenta√ß√£o.

A estrutura do projeto utiliza o padr√£o **Page Object Model (POM)** para promover reutiliza√ß√£o, manutenibilidade e clareza dos testes automatizados.

---

## ‚ö†Ô∏è Riscos e Premissas

### Riscos T√©cnicos
- ‚ùó API OCR pode ter instabilidade ou lat√™ncia imprevis√≠vel.
- ‚ùó Falta de mocks confi√°veis para testes locais da API OCR.
- ‚ùó Problemas de versionamento em bibliotecas de terceiros (ex: plugin Allure).

### Riscos Organizacionais
- ‚ùó Time de QA reduzido ou com m√∫ltiplas frentes de trabalho.
- ‚ùó Ambiente de homologa√ß√£o inst√°vel ou indispon√≠vel para testes automatizados.
- ‚ùó Aus√™ncia de defini√ß√£o clara de crit√©rios de aceite com stakeholders.

### Premissas
- ‚úÖ O ambiente de testes ser√° o mais pr√≥ximo poss√≠vel do ambiente de produ√ß√£o.
- ‚úÖ Os arquivos de exemplo utilizados nos testes representam os documentos reais do usu√°rio.
- ‚úÖ O servi√ßo de OCR est√° ativo e com respostas dentro do SLA.

---

## üîç Cen√°rios Cr√≠ticos para Testes (Pr√© Go-Live)

1. ‚úÖ **Upload bem-sucedido de um PDF v√°lido (menos de 10MB)**  
   ‚Üí Confirma que o fluxo b√°sico est√° funcionando.

2. ‚ùå **Rejei√ß√£o de arquivo PDF maior que 10MB**  
   ‚Üí Garante que regras de valida√ß√£o est√£o ativas e funcionando.

3. ‚ùå **Rejei√ß√£o de arquivos com formato inv√°lido (.jpg, .docx)**  
   ‚Üí Previne entradas incorretas no sistema.

4. üîÅ **Resili√™ncia em caso de falha na API OCR (ex: 500 ou timeout)**  
   ‚Üí Verifica tratamento de erros e mensagens amig√°veis ao usu√°rio.

5. üîç **Valida√ß√£o da resposta completa da API OCR (estrutura esperada, campos obrigat√≥rios)**  
   ‚Üí Garante a integridade dos dados extra√≠dos do PDF.

---

## üìä M√©tricas e An√°lise de Qualidade

### Indicadores Propostos

| M√©trica                         | Descri√ß√£o                                                                 |
|---------------------------------|---------------------------------------------------------------------------|
| **Cobertura de Testes (%)**     | Percentual de linhas de c√≥digo cobertas por testes unit√°rios/integrados. |
| **Tempo M√©dio de Execu√ß√£o**     | Tempo m√©dio para execu√ß√£o completa da su√≠te de testes.                   |
| **Taxa de Sucesso dos Testes**  | Propor√ß√£o de testes que passaram em rela√ß√£o ao total executado.         |
| **Falhas por Tipo de Teste**    | Quantidade de falhas categorizadas por tipo (unit√°rio, integra√ß√£o, E2E). |
| **Defeitos Cr√≠ticos por Sprint**| Quantidade de bugs cr√≠ticos identificados em produ√ß√£o/homologa√ß√£o.       |

---

### üìà Simula√ß√£o de Relat√≥rio (Execu√ß√£o Fict√≠cia)

| Tipo de Teste     | Total | Passaram | Falharam | Cobertura (%) | Tempo M√©dio |
|------------------|-------|----------|----------|----------------|--------------|
| Unit√°rios        | 120   | 120      | 0        | 92%            | 15s          |
| Integra√ß√£o       | 40    | 39       | 1        | ‚Äî              | 25s          |
| Contrato         | 10    | 10       | 0        | ‚Äî              | 5s           |
| E2E              | 18    | 17       | 1        | ‚Äî              | 1m 40s       |
| **Total**        | 188   | 186      | 2        | ‚Äî              | 2m 25s       |

---

### üìå M√©tricas Acion√°veis

As m√©tricas abaixo s√£o consideradas **acion√°veis**, ou seja, relevantes para tomada de decis√£o:

- **Falhas por Tipo de Teste:** permite priorizar corre√ß√µes onde h√° maior concentra√ß√£o de falhas (ex: E2E com falhas ‚Üí pode indicar problemas de integra√ß√£o ou dados).
- **Defeitos Cr√≠ticos por Sprint:** se bugs est√£o escapando para produ√ß√£o, √© necess√°rio revisar a estrat√©gia de testes.
- **Cobertura de Testes:** cobertura abaixo de 70% em m√≥dulos cr√≠ticos exige refor√ßo em testes unit√°rios/integrados.
- **Tempo de Execu√ß√£o da Su√≠te:** se ultrapassar o tempo limite de pipeline (ex: 10 min), pode impactar a entrega cont√≠nua.

Essas m√©tricas devem ser monitoradas a cada ciclo de entrega e discutidas com o time de produto para embasar decis√µes sobre:  
‚úÖ Prioridades de corre√ß√£o  
‚úÖ Go/No-Go para deploy  
‚úÖ D√©bitos t√©cnicos a serem tratados  

---

## üåç Cen√°rio Adicional ‚Äì Valida√ß√£o Multi-Regional e Conformidade com Privacidade

### üß≠ Estrat√©gia para Valida√ß√£o Geolocalizada

A aplica√ß√£o passou a operar em diferentes regi√µes (LATAM, EMEA, NA), sendo necess√°rio validar o comportamento regional e o tratamento de dados sens√≠veis.

#### üéØ Simula√ß√£o de Usu√°rios por Regi√£o

- Simula√ß√£o de headers de geolocaliza√ß√£o (`X-Forwarded-For`, `GeoIP`)
- Uso de proxies ou servi√ßos como BrowserStack/Geonode
- Dados formatados regionalmente:
  - **LATAM**: CPF, idioma PT-BR
  - **EMEA**: NIN (UK), idioma EN/DE/FR
  - **NA**: SSN, idioma EN-US

#### üîç Valida√ß√µes por Regi√£o

- Tradu√ß√£o/localiza√ß√£o da interface e mensagens de erro
- Valida√ß√£o de caracteres e formatos espec√≠ficos
- Diferen√ßas de lat√™ncia e comportamento sob rede limitada
- Diferencia√ß√£o de pol√≠ticas legais e consentimento

---

### ‚öôÔ∏è Testes Paralelos e Orquestra√ß√£o Distribu√≠da

#### üß™ Execu√ß√£o Paralela por Regi√£o

- **GitHub Actions Matrix Strategy**:
  ```yaml
  strategy:
    matrix:
      region: [LATAM, EMEA, NA]
      browser: [chrome, firefox]


---

## üß™ Execu√ß√£o dos Testes

Os testes automatizados est√£o escritos com **Cypress**, usando o padr√£o **Page Object Model (POM)**. Os relat√≥rios s√£o gerados com **Allure Reports** e a execu√ß√£o em CI est√° configurada com **GitHub Actions**.

## Como rodar o projeto localmente

1. Suba o servidor local da aplica√ß√£o mock OCR em http://localhost:3333/OCRAPI
2. Instale as depend√™ncias:
```bash
npm install
```
3. Execute os testes:
```bash
npm run test
```
4. Gere e abra o relat√≥rio Allure:
```bash
npm run allure:generate
npm run allure:open
```

